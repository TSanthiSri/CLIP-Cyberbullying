{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.utils import class_weight\n",
    "import pickle\n",
    "import cv2\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, auc, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"./train.jsonl\",lines=True)\n",
    "test = pd.read_json(\"./test.jsonl\",lines=True)\n",
    "valid = pd.read_json(\"./dev.jsonl\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8496, 300) (8496,)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(train['label'])\n",
    "y_train = np.delete(y_train, [9, 327, 1753, 6471], axis=0)\n",
    "x_train = np.load('train_textfeat_glove.npy')\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499, 300) (499,)\n"
     ]
    }
   ],
   "source": [
    "x_test = np.load('valid_textfeat_glove.npy')\n",
    "y_test = np.array(valid['label'])\n",
    "y_test = np.delete(y_test, [198], axis=0)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(xtrain,xtest,ytrain,ytest):\n",
    "    log_model = LogisticRegression()\n",
    "    log_model.fit(xtrain, ytrain)\n",
    "    y_pred_log = log_model.predict(xtest)\n",
    "    print(confusion_matrix(ytest, y_pred_log))\n",
    "    print(classification_report(ytest,y_pred_log))\n",
    "    #print(roc_auc_score(ytest,y_pred_log))\n",
    "    fpr, tpr, thresholds = roc_curve(ytest,y_pred_log)\n",
    "    print(auc(fpr, tpr))\n",
    "def MLP(xtrain,xtest,ytrain,ytest):\n",
    "    log_model = xgb.XGBClassifier()\n",
    "    log_model.fit(xtrain, ytrain)\n",
    "    y_pred_log = log_model.predict(xtest)\n",
    "    print(confusion_matrix(ytest, y_pred_log))\n",
    "    print(classification_report(ytest,y_pred_log))\n",
    "def LGBM(xtrain,xtest,ytrain,ytest):\n",
    "    lgbm_model = lgb.LGBMClassifier(n_estimators=1000,max_depth=5)\n",
    "    lgbm_model.fit(xtrain, ytrain)\n",
    "    y_pred_lgbm = lgbm_model.predict(xtest)\n",
    "    print(confusion_matrix(ytest, y_pred_lgbm))\n",
    "    print(classification_report(ytest,y_pred_lgbm))\n",
    "    #print(roc_auc_score(ytest,y_pred_lgbm))\n",
    "    fpr, tpr, thresholds = roc_curve(ytest,y_pred_lgbm)\n",
    "    print(auc(fpr, tpr))\n",
    "    #print(auc(ytest,y_pred_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[218  32]\n",
      " [206  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.87      0.65       250\n",
      "           1       0.57      0.17      0.27       249\n",
      "\n",
      "    accuracy                           0.52       499\n",
      "   macro avg       0.54      0.52      0.46       499\n",
      "weighted avg       0.54      0.52      0.46       499\n",
      "\n",
      "0.5223453815261044\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[[230  20]\n",
      " [211  38]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.92      0.67       250\n",
      "           1       0.66      0.15      0.25       249\n",
      "\n",
      "    accuracy                           0.54       499\n",
      "   macro avg       0.59      0.54      0.46       499\n",
      "weighted avg       0.59      0.54      0.46       499\n",
      "\n",
      "0.5363052208835342\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression')\n",
    "LR(x_train,x_test,y_train,y_test)\n",
    "print('LightGBM')\n",
    "LGBM(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[160  90]\n",
      " [133 116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.64      0.59       250\n",
      "           1       0.56      0.47      0.51       249\n",
      "\n",
      "    accuracy                           0.55       499\n",
      "   macro avg       0.55      0.55      0.55       499\n",
      "weighted avg       0.55      0.55      0.55       499\n",
      "\n",
      "0.5529317269076306\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[[219  31]\n",
      " [198  51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.88      0.66       250\n",
      "           1       0.62      0.20      0.31       249\n",
      "\n",
      "    accuracy                           0.54       499\n",
      "   macro avg       0.57      0.54      0.48       499\n",
      "weighted avg       0.57      0.54      0.48       499\n",
      "\n",
      "0.5404096385542169\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_resample(x_train, y_train)\n",
    "print('Logistic Regression')\n",
    "LR(X_ros,x_test,y_ros,y_test)\n",
    "print('LightGBM')\n",
    "LGBM(X_ros,x_test,y_ros,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over-Sampling\n",
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[163  87]\n",
      " [135 114]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.65      0.59       250\n",
      "           1       0.57      0.46      0.51       249\n",
      "\n",
      "    accuracy                           0.56       499\n",
      "   macro avg       0.56      0.55      0.55       499\n",
      "weighted avg       0.56      0.56      0.55       499\n",
      "\n",
      "0.5549156626506024\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[[182  68]\n",
      " [154  95]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.73      0.62       250\n",
      "           1       0.58      0.38      0.46       249\n",
      "\n",
      "    accuracy                           0.56       499\n",
      "   macro avg       0.56      0.55      0.54       499\n",
      "weighted avg       0.56      0.56      0.54       499\n",
      "\n",
      "0.5547630522088354\n"
     ]
    }
   ],
   "source": [
    "print('Random Over-Sampling')\n",
    "ros = RandomUnderSampler()\n",
    "X_ros, y_ros = ros.fit_resample(x_train, y_train)\n",
    "print('Logistic Regression')\n",
    "LR(X_ros,x_test,y_ros,y_test)\n",
    "print('LightGBM')\n",
    "LGBM(X_ros,x_test,y_ros,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Features Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8496, 768) (499, 768)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('train_lxmert_language_avg.npy')\n",
    "x_test = np.load('dev_lxmert_language_avg.npy')\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[208  42]\n",
      " [180  69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.83      0.65       250\n",
      "           1       0.62      0.28      0.38       249\n",
      "\n",
      "    accuracy                           0.56       499\n",
      "   macro avg       0.58      0.55      0.52       499\n",
      "weighted avg       0.58      0.56      0.52       499\n",
      "\n",
      "0.5545542168674699\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[[232  18]\n",
      " [204  45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.93      0.68       250\n",
      "           1       0.71      0.18      0.29       249\n",
      "\n",
      "    accuracy                           0.56       499\n",
      "   macro avg       0.62      0.55      0.48       499\n",
      "weighted avg       0.62      0.56      0.48       499\n",
      "\n",
      "0.5543614457831326\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression')\n",
    "LR(x_train,x_test,y_train,y_test)\n",
    "print('LightGBM')\n",
    "LGBM(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[157  93]\n",
      " [147 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.63      0.57       250\n",
      "           1       0.52      0.41      0.46       249\n",
      "\n",
      "    accuracy                           0.52       499\n",
      "   macro avg       0.52      0.52      0.51       499\n",
      "weighted avg       0.52      0.52      0.51       499\n",
      "\n",
      "0.5188192771084337\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[[219  31]\n",
      " [203  46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.88      0.65       250\n",
      "           1       0.60      0.18      0.28       249\n",
      "\n",
      "    accuracy                           0.53       499\n",
      "   macro avg       0.56      0.53      0.47       499\n",
      "weighted avg       0.56      0.53      0.47       499\n",
      "\n",
      "0.5303694779116466\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_resample(x_train, y_train)\n",
    "print('Logistic Regression')\n",
    "LR(X_ros,x_test,y_ros,y_test)\n",
    "print('LightGBM')\n",
    "LGBM(X_ros,x_test,y_ros,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over-Sampling\n",
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141 109]\n",
      " [133 116]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.56      0.54       250\n",
      "           1       0.52      0.47      0.49       249\n",
      "\n",
      "    accuracy                           0.52       499\n",
      "   macro avg       0.52      0.51      0.51       499\n",
      "weighted avg       0.52      0.52      0.51       499\n",
      "\n",
      "0.5149317269076306\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[[155  95]\n",
      " [140 109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.62      0.57       250\n",
      "           1       0.53      0.44      0.48       249\n",
      "\n",
      "    accuracy                           0.53       499\n",
      "   macro avg       0.53      0.53      0.53       499\n",
      "weighted avg       0.53      0.53      0.53       499\n",
      "\n",
      "0.5288755020080321\n"
     ]
    }
   ],
   "source": [
    "print('Random Over-Sampling')\n",
    "ros = RandomUnderSampler()\n",
    "X_ros, y_ros = ros.fit_resample(x_train, y_train)\n",
    "print('Logistic Regression')\n",
    "LR(X_ros,x_test,y_ros,y_test)\n",
    "print('LightGBM')\n",
    "LGBM(X_ros,x_test,y_ros,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Image + Text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8496, 1024)\n"
     ]
    }
   ],
   "source": [
    "x1 = np.load('train_img_feat_clip.npy')\n",
    "x2 = np.load('train_text_feat_clip.npy')\n",
    "x_train = np.concatenate([x1, x2], axis=1)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1024)\n"
     ]
    }
   ],
   "source": [
    "x1 = np.load('valid_img_feat_clip.npy')\n",
    "x2 = np.load('valid_text_feat_clip.npy')\n",
    "x_test = np.concatenate([x1, x2], axis=1)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8496, 768) (499, 768)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load('train_lxmert_pool.npy')\n",
    "x_test = np.load('dev_lxmert_pool.npy')\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[202  48]\n",
      " [188  61]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.81      0.63       250\n",
      "           1       0.56      0.24      0.34       249\n",
      "\n",
      "    accuracy                           0.53       499\n",
      "   macro avg       0.54      0.53      0.49       499\n",
      "weighted avg       0.54      0.53      0.49       499\n",
      "\n",
      "0.5264899598393574\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[[215  35]\n",
      " [205  44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.86      0.64       250\n",
      "           1       0.56      0.18      0.27       249\n",
      "\n",
      "    accuracy                           0.52       499\n",
      "   macro avg       0.53      0.52      0.46       499\n",
      "weighted avg       0.53      0.52      0.46       499\n",
      "\n",
      "0.5183534136546184\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression')\n",
    "LR(x_train,x_test,y_train,y_test)\n",
    "print('LightGBM')\n",
    "LGBM(x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[157  93]\n",
      " [132 117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.63      0.58       250\n",
      "           1       0.56      0.47      0.51       249\n",
      "\n",
      "    accuracy                           0.55       499\n",
      "   macro avg       0.55      0.55      0.55       499\n",
      "weighted avg       0.55      0.55      0.55       499\n",
      "\n",
      "0.5489397590361447\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[[214  36]\n",
      " [192  57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.86      0.65       250\n",
      "           1       0.61      0.23      0.33       249\n",
      "\n",
      "    accuracy                           0.54       499\n",
      "   macro avg       0.57      0.54      0.49       499\n",
      "weighted avg       0.57      0.54      0.49       499\n",
      "\n",
      "0.5424578313253011\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_resample(x_train, y_train)\n",
    "print('Logistic Regression')\n",
    "LR(X_ros,x_test,y_ros,y_test)\n",
    "print('LightGBM')\n",
    "LGBM(X_ros,x_test,y_ros,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over-Sampling\n",
      "Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[146 104]\n",
      " [126 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.58      0.56       250\n",
      "           1       0.54      0.49      0.52       249\n",
      "\n",
      "    accuracy                           0.54       499\n",
      "   macro avg       0.54      0.54      0.54       499\n",
      "weighted avg       0.54      0.54      0.54       499\n",
      "\n",
      "0.5389879518072289\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[[139 111]\n",
      " [118 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.56      0.55       250\n",
      "           1       0.54      0.53      0.53       249\n",
      "\n",
      "    accuracy                           0.54       499\n",
      "   macro avg       0.54      0.54      0.54       499\n",
      "weighted avg       0.54      0.54      0.54       499\n",
      "\n",
      "0.5410522088353413\n"
     ]
    }
   ],
   "source": [
    "print('Random Over-Sampling')\n",
    "ros = RandomUnderSampler()\n",
    "X_ros, y_ros = ros.fit_resample(x_train, y_train)\n",
    "print('Logistic Regression')\n",
    "LR(X_ros,x_test,y_ros,y_test)\n",
    "print('LightGBM')\n",
    "LGBM(X_ros,x_test,y_ros,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3050 5446\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y_train==1), np.sum(y_train==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
