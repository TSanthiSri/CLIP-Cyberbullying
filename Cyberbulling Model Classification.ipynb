{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.utils import class_weight\n",
    "import pickle\n",
    "import cv2\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2047, 512) (2047,)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(data['Imagelabel'])\n",
    "y = np.delete(y, [506, 2040], axis=0)\n",
    "x = np.load('img_feat_clip.npy')\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(xtrain,xtest,ytrain,ytest):\n",
    "    log_model = LogisticRegression()\n",
    "    log_model.fit(xtrain, ytrain)\n",
    "    y_pred_log = log_model.predict(xtest)\n",
    "    print(confusion_matrix(ytest, y_pred_log))\n",
    "    print(classification_report(ytest,y_pred_log))\n",
    "def MLP(xtrain,xtest,ytrain,ytest):\n",
    "    log_model = xgb.XGBClassifier()\n",
    "    log_model.fit(xtrain, ytrain)\n",
    "    y_pred_log = log_model.predict(xtest)\n",
    "    print(confusion_matrix(ytest, y_pred_log))\n",
    "    print(classification_report(ytest,y_pred_log))\n",
    "def LGBM(xtrain,xtest,ytrain,ytest):\n",
    "    lgbm_model = lgb.LGBMClassifier(n_estimators=1000,max_depth=5)\n",
    "    lgbm_model.fit(xtrain, ytrain)\n",
    "    y_pred_lgbm = lgbm_model.predict(xtest)\n",
    "    print(confusion_matrix(ytest, y_pred_lgbm))\n",
    "    print(classification_report(ytest,y_pred_lgbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[296  25]\n",
      " [ 47  42]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       321\n",
      "           1       0.63      0.47      0.54        89\n",
      "\n",
      "    accuracy                           0.82       410\n",
      "   macro avg       0.74      0.70      0.72       410\n",
      "weighted avg       0.81      0.82      0.81       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[311  10]\n",
      " [ 60  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90       321\n",
      "           1       0.74      0.33      0.45        89\n",
      "\n",
      "    accuracy                           0.83       410\n",
      "   macro avg       0.79      0.65      0.68       410\n",
      "weighted avg       0.82      0.83      0.80       410\n",
      "\n",
      "Logistic Regression\n",
      "[[278  43]\n",
      " [ 50  39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       321\n",
      "           1       0.48      0.44      0.46        89\n",
      "\n",
      "    accuracy                           0.77       410\n",
      "   macro avg       0.66      0.65      0.66       410\n",
      "weighted avg       0.77      0.77      0.77       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[307  14]\n",
      " [ 62  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       321\n",
      "           1       0.66      0.30      0.42        89\n",
      "\n",
      "    accuracy                           0.81       410\n",
      "   macro avg       0.75      0.63      0.65       410\n",
      "weighted avg       0.79      0.81      0.79       410\n",
      "\n",
      "Logistic Regression\n",
      "[[278  42]\n",
      " [ 43  46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       320\n",
      "           1       0.52      0.52      0.52        89\n",
      "\n",
      "    accuracy                           0.79       409\n",
      "   macro avg       0.69      0.69      0.69       409\n",
      "weighted avg       0.79      0.79      0.79       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[307  13]\n",
      " [ 50  39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       320\n",
      "           1       0.75      0.44      0.55        89\n",
      "\n",
      "    accuracy                           0.85       409\n",
      "   macro avg       0.80      0.70      0.73       409\n",
      "weighted avg       0.84      0.85      0.83       409\n",
      "\n",
      "Logistic Regression\n",
      "[[283  37]\n",
      " [ 45  44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       320\n",
      "           1       0.54      0.49      0.52        89\n",
      "\n",
      "    accuracy                           0.80       409\n",
      "   macro avg       0.70      0.69      0.70       409\n",
      "weighted avg       0.79      0.80      0.80       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[312   8]\n",
      " [ 62  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.90       320\n",
      "           1       0.77      0.30      0.44        89\n",
      "\n",
      "    accuracy                           0.83       409\n",
      "   macro avg       0.80      0.64      0.67       409\n",
      "weighted avg       0.82      0.83      0.80       409\n",
      "\n",
      "Logistic Regression\n",
      "[[294  26]\n",
      " [ 49  40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       320\n",
      "           1       0.61      0.45      0.52        89\n",
      "\n",
      "    accuracy                           0.82       409\n",
      "   macro avg       0.73      0.68      0.70       409\n",
      "weighted avg       0.80      0.82      0.81       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[309  11]\n",
      " [ 62  27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.97      0.89       320\n",
      "           1       0.71      0.30      0.43        89\n",
      "\n",
      "    accuracy                           0.82       409\n",
      "   macro avg       0.77      0.63      0.66       409\n",
      "weighted avg       0.81      0.82      0.79       409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for train_index, test_index in kf.split(np.arange(x.shape[0]),y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print('Logistic Regression')\n",
    "    LR(X_train,X_test,y_train,y_test)\n",
    "    print('LightGBM')\n",
    "    LGBM(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[254  67]\n",
      " [ 42  47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82       321\n",
      "           1       0.41      0.53      0.46        89\n",
      "\n",
      "    accuracy                           0.73       410\n",
      "   macro avg       0.64      0.66      0.64       410\n",
      "weighted avg       0.76      0.73      0.75       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[312   9]\n",
      " [ 60  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90       321\n",
      "           1       0.76      0.33      0.46        89\n",
      "\n",
      "    accuracy                           0.83       410\n",
      "   macro avg       0.80      0.65      0.68       410\n",
      "weighted avg       0.82      0.83      0.80       410\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[247  74]\n",
      " [ 34  55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82       321\n",
      "           1       0.43      0.62      0.50        89\n",
      "\n",
      "    accuracy                           0.74       410\n",
      "   macro avg       0.65      0.69      0.66       410\n",
      "weighted avg       0.78      0.74      0.75       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[305  16]\n",
      " [ 58  31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       321\n",
      "           1       0.66      0.35      0.46        89\n",
      "\n",
      "    accuracy                           0.82       410\n",
      "   macro avg       0.75      0.65      0.67       410\n",
      "weighted avg       0.80      0.82      0.80       410\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[241  79]\n",
      " [ 36  53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.75      0.81       320\n",
      "           1       0.40      0.60      0.48        89\n",
      "\n",
      "    accuracy                           0.72       409\n",
      "   macro avg       0.64      0.67      0.64       409\n",
      "weighted avg       0.77      0.72      0.74       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[304  16]\n",
      " [ 54  35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90       320\n",
      "           1       0.69      0.39      0.50        89\n",
      "\n",
      "    accuracy                           0.83       409\n",
      "   macro avg       0.77      0.67      0.70       409\n",
      "weighted avg       0.81      0.83      0.81       409\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[255  65]\n",
      " [ 32  57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84       320\n",
      "           1       0.47      0.64      0.54        89\n",
      "\n",
      "    accuracy                           0.76       409\n",
      "   macro avg       0.68      0.72      0.69       409\n",
      "weighted avg       0.80      0.76      0.77       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[304  16]\n",
      " [ 50  39]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       320\n",
      "           1       0.71      0.44      0.54        89\n",
      "\n",
      "    accuracy                           0.84       409\n",
      "   macro avg       0.78      0.69      0.72       409\n",
      "weighted avg       0.83      0.84      0.82       409\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[269  51]\n",
      " [ 40  49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86       320\n",
      "           1       0.49      0.55      0.52        89\n",
      "\n",
      "    accuracy                           0.78       409\n",
      "   macro avg       0.68      0.70      0.69       409\n",
      "weighted avg       0.79      0.78      0.78       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[311   9]\n",
      " [ 56  33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91       320\n",
      "           1       0.79      0.37      0.50        89\n",
      "\n",
      "    accuracy                           0.84       409\n",
      "   macro avg       0.82      0.67      0.70       409\n",
      "weighted avg       0.83      0.84      0.82       409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(np.arange(x.shape[0]),y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "    print('Random Over-Sampling')\n",
    "    ros = RandomOverSampler()\n",
    "    X_ros, y_ros = ros.fit_resample(X_train, Y_train)\n",
    "    print('Logistic Regression')\n",
    "    LR(X_ros,X_test,y_ros,Y_test)\n",
    "    print('LightGBM')\n",
    "    LGBM(X_ros,X_test,y_ros,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[227  94]\n",
      " [ 33  56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78       321\n",
      "           1       0.37      0.63      0.47        89\n",
      "\n",
      "    accuracy                           0.69       410\n",
      "   macro avg       0.62      0.67      0.63       410\n",
      "weighted avg       0.76      0.69      0.71       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[250  71]\n",
      " [ 32  57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.78      0.83       321\n",
      "           1       0.45      0.64      0.53        89\n",
      "\n",
      "    accuracy                           0.75       410\n",
      "   macro avg       0.67      0.71      0.68       410\n",
      "weighted avg       0.79      0.75      0.76       410\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[232  89]\n",
      " [ 26  63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80       321\n",
      "           1       0.41      0.71      0.52        89\n",
      "\n",
      "    accuracy                           0.72       410\n",
      "   macro avg       0.66      0.72      0.66       410\n",
      "weighted avg       0.79      0.72      0.74       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[226  95]\n",
      " [ 20  69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.70      0.80       321\n",
      "           1       0.42      0.78      0.55        89\n",
      "\n",
      "    accuracy                           0.72       410\n",
      "   macro avg       0.67      0.74      0.67       410\n",
      "weighted avg       0.81      0.72      0.74       410\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[217 103]\n",
      " [ 26  63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.68      0.77       320\n",
      "           1       0.38      0.71      0.49        89\n",
      "\n",
      "    accuracy                           0.68       409\n",
      "   macro avg       0.64      0.69      0.63       409\n",
      "weighted avg       0.78      0.68      0.71       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[219 101]\n",
      " [ 21  68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.68      0.78       320\n",
      "           1       0.40      0.76      0.53        89\n",
      "\n",
      "    accuracy                           0.70       409\n",
      "   macro avg       0.66      0.72      0.65       409\n",
      "weighted avg       0.80      0.70      0.73       409\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[223  97]\n",
      " [ 29  60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78       320\n",
      "           1       0.38      0.67      0.49        89\n",
      "\n",
      "    accuracy                           0.69       409\n",
      "   macro avg       0.63      0.69      0.63       409\n",
      "weighted avg       0.78      0.69      0.72       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[237  83]\n",
      " [ 26  63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.81       320\n",
      "           1       0.43      0.71      0.54        89\n",
      "\n",
      "    accuracy                           0.73       409\n",
      "   macro avg       0.67      0.72      0.67       409\n",
      "weighted avg       0.80      0.73      0.75       409\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[228  92]\n",
      " [ 24  65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.71      0.80       320\n",
      "           1       0.41      0.73      0.53        89\n",
      "\n",
      "    accuracy                           0.72       409\n",
      "   macro avg       0.66      0.72      0.66       409\n",
      "weighted avg       0.80      0.72      0.74       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[240  80]\n",
      " [ 20  69]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.75      0.83       320\n",
      "           1       0.46      0.78      0.58        89\n",
      "\n",
      "    accuracy                           0.76       409\n",
      "   macro avg       0.69      0.76      0.70       409\n",
      "weighted avg       0.82      0.76      0.77       409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(np.arange(x.shape[0]),y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "    print('Random Over-Sampling')\n",
    "    ros = RandomUnderSampler()\n",
    "    X_ros, y_ros = ros.fit_resample(X_train, Y_train)\n",
    "    print('Logistic Regression')\n",
    "    LR(X_ros,X_test,y_ros,Y_test)\n",
    "    print('LightGBM')\n",
    "    LGBM(X_ros,X_test,y_ros,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Features Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2047, 512) (2047,)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(data['Comment label'])\n",
    "y = np.delete(y, [506, 2040], axis=0)\n",
    "x = np.load('text_feat_clip.npy')\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[200  35]\n",
      " [ 39 136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       235\n",
      "           1       0.80      0.78      0.79       175\n",
      "\n",
      "    accuracy                           0.82       410\n",
      "   macro avg       0.82      0.81      0.82       410\n",
      "weighted avg       0.82      0.82      0.82       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[206  29]\n",
      " [ 52 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       235\n",
      "           1       0.81      0.70      0.75       175\n",
      "\n",
      "    accuracy                           0.80       410\n",
      "   macro avg       0.80      0.79      0.79       410\n",
      "weighted avg       0.80      0.80      0.80       410\n",
      "\n",
      "Logistic Regression\n",
      "[[192  43]\n",
      " [ 45 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81       235\n",
      "           1       0.75      0.74      0.75       175\n",
      "\n",
      "    accuracy                           0.79       410\n",
      "   macro avg       0.78      0.78      0.78       410\n",
      "weighted avg       0.79      0.79      0.79       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[200  35]\n",
      " [ 55 120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.82       235\n",
      "           1       0.77      0.69      0.73       175\n",
      "\n",
      "    accuracy                           0.78       410\n",
      "   macro avg       0.78      0.77      0.77       410\n",
      "weighted avg       0.78      0.78      0.78       410\n",
      "\n",
      "Logistic Regression\n",
      "[[197  38]\n",
      " [ 51 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       235\n",
      "           1       0.76      0.71      0.73       174\n",
      "\n",
      "    accuracy                           0.78       409\n",
      "   macro avg       0.78      0.77      0.78       409\n",
      "weighted avg       0.78      0.78      0.78       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[201  34]\n",
      " [ 54 120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       235\n",
      "           1       0.78      0.69      0.73       174\n",
      "\n",
      "    accuracy                           0.78       409\n",
      "   macro avg       0.78      0.77      0.78       409\n",
      "weighted avg       0.78      0.78      0.78       409\n",
      "\n",
      "Logistic Regression\n",
      "[[200  35]\n",
      " [ 38 136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85       235\n",
      "           1       0.80      0.78      0.79       174\n",
      "\n",
      "    accuracy                           0.82       409\n",
      "   macro avg       0.82      0.82      0.82       409\n",
      "weighted avg       0.82      0.82      0.82       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[209  26]\n",
      " [ 44 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       235\n",
      "           1       0.83      0.75      0.79       174\n",
      "\n",
      "    accuracy                           0.83       409\n",
      "   macro avg       0.83      0.82      0.82       409\n",
      "weighted avg       0.83      0.83      0.83       409\n",
      "\n",
      "Logistic Regression\n",
      "[[198  37]\n",
      " [ 47 127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83       235\n",
      "           1       0.77      0.73      0.75       174\n",
      "\n",
      "    accuracy                           0.79       409\n",
      "   macro avg       0.79      0.79      0.79       409\n",
      "weighted avg       0.79      0.79      0.79       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[209  26]\n",
      " [ 48 126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       235\n",
      "           1       0.83      0.72      0.77       174\n",
      "\n",
      "    accuracy                           0.82       409\n",
      "   macro avg       0.82      0.81      0.81       409\n",
      "weighted avg       0.82      0.82      0.82       409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for train_index, test_index in kf.split(np.arange(x.shape[0]),y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print('Logistic Regression')\n",
    "    LR(X_train,X_test,y_train,y_test)\n",
    "    print('LightGBM')\n",
    "    LGBM(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[196  39]\n",
      " [ 35 140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       235\n",
      "           1       0.78      0.80      0.79       175\n",
      "\n",
      "    accuracy                           0.82       410\n",
      "   macro avg       0.82      0.82      0.82       410\n",
      "weighted avg       0.82      0.82      0.82       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[211  24]\n",
      " [ 40 135]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       235\n",
      "           1       0.85      0.77      0.81       175\n",
      "\n",
      "    accuracy                           0.84       410\n",
      "   macro avg       0.84      0.83      0.84       410\n",
      "weighted avg       0.84      0.84      0.84       410\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[203  32]\n",
      " [ 36 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86       235\n",
      "           1       0.81      0.79      0.80       175\n",
      "\n",
      "    accuracy                           0.83       410\n",
      "   macro avg       0.83      0.83      0.83       410\n",
      "weighted avg       0.83      0.83      0.83       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[216  19]\n",
      " [ 53 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86       235\n",
      "           1       0.87      0.70      0.77       175\n",
      "\n",
      "    accuracy                           0.82       410\n",
      "   macro avg       0.83      0.81      0.81       410\n",
      "weighted avg       0.83      0.82      0.82       410\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[190  45]\n",
      " [ 37 137]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       235\n",
      "           1       0.75      0.79      0.77       174\n",
      "\n",
      "    accuracy                           0.80       409\n",
      "   macro avg       0.79      0.80      0.80       409\n",
      "weighted avg       0.80      0.80      0.80       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[199  36]\n",
      " [ 54 120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       235\n",
      "           1       0.77      0.69      0.73       174\n",
      "\n",
      "    accuracy                           0.78       409\n",
      "   macro avg       0.78      0.77      0.77       409\n",
      "weighted avg       0.78      0.78      0.78       409\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[182  53]\n",
      " [ 37 137]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80       235\n",
      "           1       0.72      0.79      0.75       174\n",
      "\n",
      "    accuracy                           0.78       409\n",
      "   macro avg       0.78      0.78      0.78       409\n",
      "weighted avg       0.78      0.78      0.78       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[196  39]\n",
      " [ 49 125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       235\n",
      "           1       0.76      0.72      0.74       174\n",
      "\n",
      "    accuracy                           0.78       409\n",
      "   macro avg       0.78      0.78      0.78       409\n",
      "weighted avg       0.78      0.78      0.78       409\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[190  45]\n",
      " [ 43 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       235\n",
      "           1       0.74      0.75      0.75       174\n",
      "\n",
      "    accuracy                           0.78       409\n",
      "   macro avg       0.78      0.78      0.78       409\n",
      "weighted avg       0.79      0.78      0.78       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[199  36]\n",
      " [ 46 128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       235\n",
      "           1       0.78      0.74      0.76       174\n",
      "\n",
      "    accuracy                           0.80       409\n",
      "   macro avg       0.80      0.79      0.79       409\n",
      "weighted avg       0.80      0.80      0.80       409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(np.arange(x.shape[0]),y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "    print('Random Over-Sampling')\n",
    "    ros = RandomOverSampler()\n",
    "    X_ros, y_ros = ros.fit_resample(X_train, Y_train)\n",
    "    print('Logistic Regression')\n",
    "    LR(X_ros,X_test,y_ros,Y_test)\n",
    "    print('LightGBM')\n",
    "    LGBM(X_ros,X_test,y_ros,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[180  55]\n",
      " [ 53 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       235\n",
      "           1       0.69      0.70      0.69       175\n",
      "\n",
      "    accuracy                           0.74       410\n",
      "   macro avg       0.73      0.73      0.73       410\n",
      "weighted avg       0.74      0.74      0.74       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[192  43]\n",
      " [ 58 117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79       235\n",
      "           1       0.73      0.67      0.70       175\n",
      "\n",
      "    accuracy                           0.75       410\n",
      "   macro avg       0.75      0.74      0.75       410\n",
      "weighted avg       0.75      0.75      0.75       410\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[192  43]\n",
      " [ 35 140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83       235\n",
      "           1       0.77      0.80      0.78       175\n",
      "\n",
      "    accuracy                           0.81       410\n",
      "   macro avg       0.81      0.81      0.81       410\n",
      "weighted avg       0.81      0.81      0.81       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[195  40]\n",
      " [ 40 135]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       235\n",
      "           1       0.77      0.77      0.77       175\n",
      "\n",
      "    accuracy                           0.80       410\n",
      "   macro avg       0.80      0.80      0.80       410\n",
      "weighted avg       0.80      0.80      0.80       410\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[190  45]\n",
      " [ 31 143]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83       235\n",
      "           1       0.76      0.82      0.79       174\n",
      "\n",
      "    accuracy                           0.81       409\n",
      "   macro avg       0.81      0.82      0.81       409\n",
      "weighted avg       0.82      0.81      0.81       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[191  44]\n",
      " [ 32 142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83       235\n",
      "           1       0.76      0.82      0.79       174\n",
      "\n",
      "    accuracy                           0.81       409\n",
      "   macro avg       0.81      0.81      0.81       409\n",
      "weighted avg       0.82      0.81      0.81       409\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[197  38]\n",
      " [ 32 142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85       235\n",
      "           1       0.79      0.82      0.80       174\n",
      "\n",
      "    accuracy                           0.83       409\n",
      "   macro avg       0.82      0.83      0.83       409\n",
      "weighted avg       0.83      0.83      0.83       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[198  37]\n",
      " [ 42 132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       235\n",
      "           1       0.78      0.76      0.77       174\n",
      "\n",
      "    accuracy                           0.81       409\n",
      "   macro avg       0.80      0.80      0.80       409\n",
      "weighted avg       0.81      0.81      0.81       409\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[180  55]\n",
      " [ 34 140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80       235\n",
      "           1       0.72      0.80      0.76       174\n",
      "\n",
      "    accuracy                           0.78       409\n",
      "   macro avg       0.78      0.79      0.78       409\n",
      "weighted avg       0.79      0.78      0.78       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197  38]\n",
      " [ 37 137]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       235\n",
      "           1       0.78      0.79      0.79       174\n",
      "\n",
      "    accuracy                           0.82       409\n",
      "   macro avg       0.81      0.81      0.81       409\n",
      "weighted avg       0.82      0.82      0.82       409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(np.arange(x.shape[0]),y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "    print('Random Over-Sampling')\n",
    "    ros = RandomUnderSampler()\n",
    "    X_ros, y_ros = ros.fit_resample(X_train, Y_train)\n",
    "    print('Logistic Regression')\n",
    "    LR(X_ros,X_test,y_ros,Y_test)\n",
    "    print('LightGBM')\n",
    "    LGBM(X_ros,X_test,y_ros,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Image + Text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2047, 1024)\n"
     ]
    }
   ],
   "source": [
    "img_features = np.load('img_feat_clip.npy')\n",
    "text_features = np.load('text_feat_clip.npy')\n",
    "x = np.concatenate([img_features, text_features], axis=1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2047,)\n"
     ]
    }
   ],
   "source": [
    "combined = np.array(data['Combined label'])\n",
    "y = np.delete(combined, [506, 2040], axis=0)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[ 76  46]\n",
      " [ 53 235]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61       122\n",
      "           1       0.84      0.82      0.83       288\n",
      "\n",
      "    accuracy                           0.76       410\n",
      "   macro avg       0.71      0.72      0.72       410\n",
      "weighted avg       0.76      0.76      0.76       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 58  64]\n",
      " [ 21 267]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.48      0.58       122\n",
      "           1       0.81      0.93      0.86       288\n",
      "\n",
      "    accuracy                           0.79       410\n",
      "   macro avg       0.77      0.70      0.72       410\n",
      "weighted avg       0.79      0.79      0.78       410\n",
      "\n",
      "Logistic Regression\n",
      "[[ 61  61]\n",
      " [ 38 250]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.50      0.55       122\n",
      "           1       0.80      0.87      0.83       288\n",
      "\n",
      "    accuracy                           0.76       410\n",
      "   macro avg       0.71      0.68      0.69       410\n",
      "weighted avg       0.75      0.76      0.75       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 48  74]\n",
      " [ 15 273]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.39      0.52       122\n",
      "           1       0.79      0.95      0.86       288\n",
      "\n",
      "    accuracy                           0.78       410\n",
      "   macro avg       0.77      0.67      0.69       410\n",
      "weighted avg       0.78      0.78      0.76       410\n",
      "\n",
      "Logistic Regression\n",
      "[[ 68  54]\n",
      " [ 36 251]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60       122\n",
      "           1       0.82      0.87      0.85       287\n",
      "\n",
      "    accuracy                           0.78       409\n",
      "   macro avg       0.74      0.72      0.72       409\n",
      "weighted avg       0.77      0.78      0.77       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 54  68]\n",
      " [ 19 268]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.44      0.55       122\n",
      "           1       0.80      0.93      0.86       287\n",
      "\n",
      "    accuracy                           0.79       409\n",
      "   macro avg       0.77      0.69      0.71       409\n",
      "weighted avg       0.78      0.79      0.77       409\n",
      "\n",
      "Logistic Regression\n",
      "[[ 68  54]\n",
      " [ 48 239]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.56      0.57       122\n",
      "           1       0.82      0.83      0.82       287\n",
      "\n",
      "    accuracy                           0.75       409\n",
      "   macro avg       0.70      0.70      0.70       409\n",
      "weighted avg       0.75      0.75      0.75       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59  63]\n",
      " [ 25 262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.48      0.57       122\n",
      "           1       0.81      0.91      0.86       287\n",
      "\n",
      "    accuracy                           0.78       409\n",
      "   macro avg       0.75      0.70      0.71       409\n",
      "weighted avg       0.78      0.78      0.77       409\n",
      "\n",
      "Logistic Regression\n",
      "[[ 67  55]\n",
      " [ 42 245]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.55      0.58       122\n",
      "           1       0.82      0.85      0.83       287\n",
      "\n",
      "    accuracy                           0.76       409\n",
      "   macro avg       0.72      0.70      0.71       409\n",
      "weighted avg       0.76      0.76      0.76       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 65  57]\n",
      " [ 19 268]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.53      0.63       122\n",
      "           1       0.82      0.93      0.88       287\n",
      "\n",
      "    accuracy                           0.81       409\n",
      "   macro avg       0.80      0.73      0.75       409\n",
      "weighted avg       0.81      0.81      0.80       409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for train_index, test_index in kf.split(np.arange(x.shape[0]),y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print('Logistic Regression')\n",
    "    LR(X_train,X_test,y_train,y_test)\n",
    "    print('LightGBM')\n",
    "    LGBM(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[ 66  56]\n",
      " [ 58 230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.54       122\n",
      "           1       0.80      0.80      0.80       288\n",
      "\n",
      "    accuracy                           0.72       410\n",
      "   macro avg       0.67      0.67      0.67       410\n",
      "weighted avg       0.72      0.72      0.72       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 55  67]\n",
      " [ 26 262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.45      0.54       122\n",
      "           1       0.80      0.91      0.85       288\n",
      "\n",
      "    accuracy                           0.77       410\n",
      "   macro avg       0.74      0.68      0.70       410\n",
      "weighted avg       0.76      0.77      0.76       410\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[ 75  47]\n",
      " [ 55 233]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.60       122\n",
      "           1       0.83      0.81      0.82       288\n",
      "\n",
      "    accuracy                           0.75       410\n",
      "   macro avg       0.70      0.71      0.71       410\n",
      "weighted avg       0.76      0.75      0.75       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 67  55]\n",
      " [ 12 276]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.55      0.67       122\n",
      "           1       0.83      0.96      0.89       288\n",
      "\n",
      "    accuracy                           0.84       410\n",
      "   macro avg       0.84      0.75      0.78       410\n",
      "weighted avg       0.84      0.84      0.82       410\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[ 73  49]\n",
      " [ 42 245]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.60      0.62       122\n",
      "           1       0.83      0.85      0.84       287\n",
      "\n",
      "    accuracy                           0.78       409\n",
      "   macro avg       0.73      0.73      0.73       409\n",
      "weighted avg       0.77      0.78      0.78       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56  66]\n",
      " [ 22 265]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.46      0.56       122\n",
      "           1       0.80      0.92      0.86       287\n",
      "\n",
      "    accuracy                           0.78       409\n",
      "   macro avg       0.76      0.69      0.71       409\n",
      "weighted avg       0.78      0.78      0.77       409\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[ 68  54]\n",
      " [ 67 220]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.56      0.53       122\n",
      "           1       0.80      0.77      0.78       287\n",
      "\n",
      "    accuracy                           0.70       409\n",
      "   macro avg       0.65      0.66      0.66       409\n",
      "weighted avg       0.71      0.70      0.71       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56  66]\n",
      " [ 36 251]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.46      0.52       122\n",
      "           1       0.79      0.87      0.83       287\n",
      "\n",
      "    accuracy                           0.75       409\n",
      "   macro avg       0.70      0.67      0.68       409\n",
      "weighted avg       0.74      0.75      0.74       409\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[ 78  44]\n",
      " [ 74 213]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.64      0.57       122\n",
      "           1       0.83      0.74      0.78       287\n",
      "\n",
      "    accuracy                           0.71       409\n",
      "   macro avg       0.67      0.69      0.68       409\n",
      "weighted avg       0.73      0.71      0.72       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 63  59]\n",
      " [ 27 260]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.52      0.59       122\n",
      "           1       0.82      0.91      0.86       287\n",
      "\n",
      "    accuracy                           0.79       409\n",
      "   macro avg       0.76      0.71      0.73       409\n",
      "weighted avg       0.78      0.79      0.78       409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(np.arange(x.shape[0]),y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "    print('Random Over-Sampling')\n",
    "    ros = RandomOverSampler()\n",
    "    X_ros, y_ros = ros.fit_resample(X_train, Y_train)\n",
    "    print('Logistic Regression')\n",
    "    LR(X_ros,X_test,y_ros,Y_test)\n",
    "    print('LightGBM')\n",
    "    LGBM(X_ros,X_test,y_ros,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Under-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[ 96  26]\n",
      " [ 93 195]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.79      0.62       122\n",
      "           1       0.88      0.68      0.77       288\n",
      "\n",
      "    accuracy                           0.71       410\n",
      "   macro avg       0.70      0.73      0.69       410\n",
      "weighted avg       0.77      0.71      0.72       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 93  29]\n",
      " [ 71 217]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.76      0.65       122\n",
      "           1       0.88      0.75      0.81       288\n",
      "\n",
      "    accuracy                           0.76       410\n",
      "   macro avg       0.72      0.76      0.73       410\n",
      "weighted avg       0.79      0.76      0.76       410\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[ 80  42]\n",
      " [ 87 201]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.66      0.55       122\n",
      "           1       0.83      0.70      0.76       288\n",
      "\n",
      "    accuracy                           0.69       410\n",
      "   macro avg       0.65      0.68      0.66       410\n",
      "weighted avg       0.72      0.69      0.70       410\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 87  35]\n",
      " [ 66 222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.71      0.63       122\n",
      "           1       0.86      0.77      0.81       288\n",
      "\n",
      "    accuracy                           0.75       410\n",
      "   macro avg       0.72      0.74      0.72       410\n",
      "weighted avg       0.78      0.75      0.76       410\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[ 85  37]\n",
      " [ 80 207]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.70      0.59       122\n",
      "           1       0.85      0.72      0.78       287\n",
      "\n",
      "    accuracy                           0.71       409\n",
      "   macro avg       0.68      0.71      0.69       409\n",
      "weighted avg       0.75      0.71      0.72       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 87  35]\n",
      " [ 74 213]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.71      0.61       122\n",
      "           1       0.86      0.74      0.80       287\n",
      "\n",
      "    accuracy                           0.73       409\n",
      "   macro avg       0.70      0.73      0.71       409\n",
      "weighted avg       0.76      0.73      0.74       409\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[ 88  34]\n",
      " [ 78 209]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.72      0.61       122\n",
      "           1       0.86      0.73      0.79       287\n",
      "\n",
      "    accuracy                           0.73       409\n",
      "   macro avg       0.70      0.72      0.70       409\n",
      "weighted avg       0.76      0.73      0.74       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 85  37]\n",
      " [ 66 221]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.70      0.62       122\n",
      "           1       0.86      0.77      0.81       287\n",
      "\n",
      "    accuracy                           0.75       409\n",
      "   macro avg       0.71      0.73      0.72       409\n",
      "weighted avg       0.77      0.75      0.75       409\n",
      "\n",
      "Random Over-Sampling\n",
      "Logistic Regression\n",
      "[[ 95  27]\n",
      " [ 79 208]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.78      0.64       122\n",
      "           1       0.89      0.72      0.80       287\n",
      "\n",
      "    accuracy                           0.74       409\n",
      "   macro avg       0.72      0.75      0.72       409\n",
      "weighted avg       0.78      0.74      0.75       409\n",
      "\n",
      "LightGBM\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbainria/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 97  25]\n",
      " [ 74 213]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.66       122\n",
      "           1       0.89      0.74      0.81       287\n",
      "\n",
      "    accuracy                           0.76       409\n",
      "   macro avg       0.73      0.77      0.74       409\n",
      "weighted avg       0.80      0.76      0.77       409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(np.arange(x.shape[0]),y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "    print('Random Over-Sampling')\n",
    "    ros = RandomUnderSampler()\n",
    "    X_ros, y_ros = ros.fit_resample(X_train, Y_train)\n",
    "    print('Logistic Regression')\n",
    "    LR(X_ros,X_test,y_ros,Y_test)\n",
    "    print('LightGBM')\n",
    "    LGBM(X_ros,X_test,y_ros,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1439\n",
       "0     610\n",
       "Name: Combined label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Combined label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1603\n",
       "1     446\n",
       "Name: Imagelabel, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Imagelabel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1176\n",
       "1     873\n",
       "Name: Comment label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Comment label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Imageid', 'Imagelabel', 'Comment', 'Comment label', 'Combined label'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
